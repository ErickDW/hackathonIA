{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6de68937-ad19-421e-8231-a5b2e17ff8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from telegram import InlineKeyboardButton, InlineKeyboardMarkup\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackQueryHandler\n",
    "import google.generativeai as genai\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- CONFIGURACIÓN DE CLAVES ---\n",
    "TELEGRAM_TOKEN = \"8168970659:AAHePkOp151khG4aP5svIYj2qTtxTXM6tFM\"\n",
    "GEMINI_API_KEY = \"AIzaSyCRiJcX3288ch-Sak-f82E65htU7tLk3Ms\"\n",
    "\n",
    "# Configura la API de Gemini\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Configura el modelo de Gemini que vamos a usar\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ccefea8-e259-457f-9d44-b3322409ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONOCIMIENTO DE LA EMPRESA ---\n",
    "# Pega aquí toda la información que quieres que el bot sepa.\n",
    "# Puedes usar el formato que quieras, pero pregunta/respuesta es muy efectivo.\n",
    "\n",
    "FAQ_INGELEAN = \"\"\"\n",
    "INFORMACIÓN BASE DE INGELEAN:\n",
    "\n",
    "Pregunta: ¿Qué es Ingelean?\n",
    "Respuesta: Ingelean es una consultora de ingeniería y gestión de activos que se especializa en optimizar la productividad y la eficiencia de empresas industriales a través de la metodología Lean Manufacturing y la innovación tecnológica.\n",
    "\n",
    "Pregunta: ¿Dónde están ubicados?\n",
    "Respuesta: Nuestra sede principal está en Cl. 29 #10-23, La victoria, Pereira, Risaralda, pero ofrecemos servicios a nivel nacional e internacional.\n",
    "\n",
    "Pregunta: ¿Cómo puedo contactarlos?\n",
    "Respuesta: Puedes contactarnos a través del formulario en nuestro sitio web ingelean.com o llamando al 311 4196803.\n",
    "\n",
    "\n",
    "Pregunta: ¿Qué servicios ofrece IngeLean para mi empresa?\n",
    "Respuesta:  En IngeLean te ayudamos a digitalizar y automatizar tus procesos. Desarrollamos soluciones tecnológicas a la medida y también contamos con productos listos para usar como IngeLean Plus. Nos adaptamos a tus necesidades.\n",
    "\n",
    "\n",
    "Pregunta: ¿Cuánto cuesta un software personalizado con ustedes?\n",
    "Respuesta: El precio depende del alcance del proyecto y las funcionalidades. Si deseas, podemos agendar una reunión gratuita para entender mejor tus necesidades y darte una cotización estimada.\n",
    "\n",
    "\n",
    "Pregunta: ¿Pueden integrar sus soluciones con mi sistema actual?\n",
    "Respuesta: Sí, claro. Nuestras soluciones pueden integrarse con sistemas existentes, como ERPs, CRMs o bases de datos. Siempre buscamos que todo fluya sin fricciones.\n",
    "\n",
    "\n",
    "Pregunta: ¿Cuánto tiempo tarda desarrollar una solución a la medida?\n",
    "Respuesta: El tiempo varía según la complejidad del proyecto. Hemos hecho soluciones que toman desde 2 semanas hasta varios meses. Siempre trabajamos con entregas parciales para que veas avances constantes.\n",
    "\n",
    "\n",
    "Pregunta: ¿Ustedes manejan datos sensibles de mis clientes? ¿Cómo los protegen?\n",
    "Respuesta: Sí, y los tratamos con total responsabilidad. Aplicamos protocolos de seguridad, cifrado y seguimos buenas prácticas de protección de datos. La privacidad de tus clientes es prioridad.\n",
    "\n",
    "\n",
    "Pregunta: ¿Puedo ver un demo de sus productos antes de comprar?\n",
    "Respuesta: ¡Por supuesto! Podemos mostrarte demos de IngeLean Plus o ejemplos de proyectos anteriores. Escríbenos y agendamos una demo sin compromiso.\n",
    "\n",
    "\n",
    "Pregunta:¿Qué industrias atienden o con cuáles han trabajado?\n",
    "Respuesta: Hemos trabajado con empresas del sector industrial, logístico, salud, energía, manufactura, agro y más. Nuestra experiencia es amplia y nos encanta adaptarnos a nuevos retos.\n",
    "\n",
    "\n",
    "Pregunta: ¿Qué diferencia a IngeLean de otras empresas de tecnología?\n",
    "Respuesta: Nos enfocamos en soluciones prácticas, con rápida implementación y un acompañamiento cercano. No te vendemos solo tecnología: te ayudamos a transformar tus procesos.\n",
    "\n",
    "\n",
    "Pregunta:¿Ustedes hacen mantenimiento y soporte después de la entrega?\n",
    "Respuesta: Sí, ofrecemos soporte técnico, mantenimiento y mejoras continuas. No te dejamos solo después de la entrega, estamos para acompañarte siempre.\n",
    "\n",
    "\n",
    "Pregunta: ¿IngeLean me ayuda a automatizar mis procesos internos?\n",
    "Respuesta: ¡Exactamente! Eso es lo que hacemos mejor. Digitalizamos y automatizamos tareas manuales para que tu empresa sea más ágil, eficiente y rentable.\n",
    "\n",
    "\n",
    "Pregunta: ¿Qué pasa si no sé exactamente lo que necesito, me asesoran?\n",
    "Respuesta: Claro que sí. Podemos hacer un diagnóstico gratuito y ayudarte a identificar oportunidades de mejora. Nos encanta ayudarte a encontrar la mejor solución, aunque aún no esté clara.\n",
    "\n",
    "\n",
    "Pregunta: ¿Tienen casos de éxito que puedan mostrarme?\n",
    "Respuesta: ¡Sí! Tenemos varios casos de éxito en diferentes industrias. Escríbenos y te compartimos ejemplos concretos de cómo hemos ayudado a otras empresas como la tuya.\n",
    "\n",
    "\n",
    "Pregunta: ¿IngeLean puede ayudarme a digitalizar mis procesos en planta?\n",
    "Respuesta: Sí. Hemos trabajado en digitalización de producción, control de calidad, trazabilidad, mantenimiento y más. Podemos ayudarte a que tu planta sea más conectada y eficiente.\n",
    "\n",
    "\n",
    "Pregunta:  ¿Se puede empezar con algo básico e ir escalando después?\n",
    "Respuesta: Por supuesto. Podemos comenzar con una solución mínima viable y luego ir construyendo sobre ella. Esto te permite tener resultados rápidos y ajustar sobre la marcha.\n",
    "\n",
    "\n",
    "Pregunta: ¿Tienen servicio de soporte técnico o mesa de ayuda?\n",
    "Respuesta: Sí, ofrecemos soporte técnico y mesa de ayuda según el nivel que necesites. Estamos disponibles para resolver problemas, capacitar a tu equipo o mejorar el sistema.\n",
    "\n",
    "\n",
    "Pregunta:¿Puedo personalizar completamente la solución o es un paquete cerrado?\n",
    "Respuesta: Ambas opciones son posibles. Si eliges una solución a la medida, es completamente personalizada. Si eliges IngeLean Plus, puedes configurarla según tus procesos y agregarle módulos extra.\n",
    "\n",
    "--- FIN DE LA INFORMACIÓN ---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d320ce1-67aa-44d2-9f95-598cbe77398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando el conocimiento del bot...\n",
      "Intentando extraer texto de: https://ingelean.com/\n",
      "Extracción de texto web exitosa.\n",
      "Conocimiento del bot preparado.\n"
     ]
    }
   ],
   "source": [
    "# --- 4.2: Función para Extraer Texto de la Web ---\n",
    "def obtener_texto_web(url):\n",
    "    \"\"\"Extrae todo el texto visible de una URL.\"\"\"\n",
    "    print(f\"Intentando extraer texto de: {url}\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        texto = soup.get_text()\n",
    "        lineas = (line.strip() for line in texto.splitlines())\n",
    "        chunks = (phrase.strip() for line in lineas for phrase in line.split(\"  \"))\n",
    "        texto_limpio = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        print(\"Extracción de texto web exitosa.\")\n",
    "        return texto_limpio\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error al obtener la URL {url}: {e}\")\n",
    "        return \"No se pudo cargar la información del sitio web.\"\n",
    "\n",
    "# --- 4.3: Combinar todo el conocimiento en una sola variable ---\n",
    "print(\"Preparando el conocimiento del bot...\")\n",
    "contexto_web = obtener_texto_web(\"https://ingelean.com/\")\n",
    "CONOCIMIENTO_INGELEAN = f\"\"\"\n",
    "{FAQ_INGELEAN}\n",
    "\n",
    "--- Contenido general extraído de ingelean.com ---\n",
    "{contexto_web}\n",
    "\"\"\"\n",
    "print(\"Conocimiento del bot preparado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4bb1fa-25cf-4776-b166-e83de32b90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# SECCIÓN 5: LÓGICA CENTRAL DE RESPUESTA\n",
    "# ==============================================================================\n",
    "\n",
    "async def process_and_reply(update, context, user_question):\n",
    "    \"\"\"\n",
    "    Función central que procesa una pregunta, la envía a Gemini y responde\n",
    "    con texto o con botones si no encuentra la respuesta.\n",
    "    \"\"\"\n",
    "    message_to_reply = update.message or update.callback_query.message\n",
    "    \n",
    "    reglas = \"\"\"\n",
    "    Eres un asistente virtual experto de la empresa Ingelean. Tu nombre es 'LeanBot'.\n",
    "    Tu única función es responder preguntas sobre Ingelean basándote ESTRICTAMENTE en la información que te proporciono.\n",
    "    Sé amable, profesional y directo.\n",
    "    Si la pregunta del usuario NO se puede responder con la información proporcionada, tu única respuesta debe ser la frase exacta: NO_SE_LA_RESPUESTA\n",
    "    NO inventes respuestas. NO hables de otros temas.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_completo = f\"\"\"{reglas}\\n\\n--- INFORMACIÓN DE CONTEXTO ---\\n{CONOCIMIENTO_INGELEAN}\\n--- FIN DEL CONTEXTO ---\\n\\nPREGUNTA DEL USUARIO: \"{user_question}\"\\n\\nRESPUESTA:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt_completo)\n",
    "        \n",
    "        if \"NO_SE_LA_RESPUESTA\" in response.text:\n",
    "            keyboard = [\n",
    "                [InlineKeyboardButton(\"¿Qué servicios ofrecen?\", callback_data=\"¿Qué servicios ofrecen?\")],\n",
    "                [InlineKeyboardButton(\"Háblame sobre Lean\", callback_data=\"¿Qué es la metodología Lean Manufacturing?\")],\n",
    "                [InlineKeyboardButton(\"¿Cómo los contacto?\", callback_data=\"¿Cómo puedo contactarlos?\")],\n",
    "            ]\n",
    "            reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "            await message_to_reply.reply_text(\n",
    "                \"Lo siento, no encontré una respuesta para eso. Solo puedo ayudarte con información sobre Ingelean. Quizás te interese alguna de estas opciones:\",\n",
    "                reply_markup=reply_markup\n",
    "            )\n",
    "        else:\n",
    "            await message_to_reply.reply_text(response.text)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la pregunta '{user_question}': {e}\")\n",
    "        await message_to_reply.reply_text('Lo siento, ha ocurrido un error al procesar tu solicitud.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3241d7-b527-465d-ae21-adfcfcd48249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# NUEVA FUNCIÓN CENTRAL PARA RESPONDER\n",
    "# ==============================================================================\n",
    "\n",
    "async def process_and_reply(update, context, user_question):\n",
    "    \"\"\"\n",
    "    Función central que toma una pregunta (texto), la procesa con Gemini,\n",
    "    y envía una respuesta normal o los botones de opciones.\n",
    "    \"\"\"\n",
    "    # El objeto `message` puede venir de un mensaje de texto o de un callback de botón\n",
    "    message_to_reply = update.message or update.callback_query.message\n",
    "\n",
    "    # 1. Construir el prompt con las reglas y el contexto\n",
    "    reglas = \"\"\"\n",
    "    Eres un agente virtual experto de la empresa Ingelean. Tu nombre es 'LeanBot'.\n",
    "    Tu única función es responder preguntas sobre Ingelean basándote ESTRICTAMENTE en la información que te proporciono.\n",
    "    Sé amable, profesional y directo.\n",
    "    Si la pregunta del usuario NO se puede responder con la información proporcionada, tu única respuesta debe ser la frase exacta: NO_SE_LA_RESPUESTA\n",
    "    NO inventes respuestas. NO hables de otros temas.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_completo = f\"\"\"\n",
    "    {reglas}\n",
    "    --- INFORMACIÓN DE CONTEXTO PARA RESPONDER ---\n",
    "    {CONOCIMIENTO_INGELEAN}\n",
    "    --- FIN DEL CONTEXTO ---\n",
    "    PREGUNTA DEL USUARIO: \"{user_question}\"\n",
    "    RESPUESTA:\n",
    "    \"\"\"\n",
    "    \n",
    "    # 2. Contactar a Gemini y manejar la respuesta\n",
    "    try:\n",
    "        response = model.generate_content(prompt_completo)\n",
    "        \n",
    "        if \"NO_SE_LA_RESPUESTA\" in response.text:\n",
    "            # Si no sabe, crear y mostrar los botones\n",
    "            keyboard = [\n",
    "                [InlineKeyboardButton(\"¿Qué servicios ofrecen?\", callback_data=\"¿Qué servicios ofrecen?\")],\n",
    "                [InlineKeyboardButton(\"Háblame sobre la metodología Lean\", callback_data=\"¿Qué es la metodología Lean Manufacturing?\")],\n",
    "                [InlineKeyboardButton(\"¿Cómo puedo contactarlos?\", callback_data=\"¿Cómo puedo contactarlos?\")],\n",
    "            ]\n",
    "            reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "            await message_to_reply.reply_text(\n",
    "                \"Lo siento, no encontré una respuesta para eso. Solo puedo ayudarte con información sobre Ingelean. Quizás te interese preguntar por alguna de estas opciones:\",\n",
    "                reply_markup=reply_markup\n",
    "            )\n",
    "        else:\n",
    "            # Si sí sabe, enviar la respuesta normal\n",
    "            await message_to_reply.reply_text(response.text)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la pregunta '{user_question}': {e}\")\n",
    "        await message_to_reply.reply_text('Lo siento, ha ocurrido un error al procesar tu solicitud.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2a3c1d8-7d58-4084-ad10-fa8fa3bb6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start(update, context):\n",
    "    \"\"\"Envía un mensaje de bienvenida.\"\"\"\n",
    "    await update.message.reply_text('¡Hola! Soy LeanBot, el asistente virtual de Ingelean. ¿En qué puedo ayudarte hoy? Puedes escribirme o enviarme un mensaje de voz.')\n",
    "\n",
    "async def handle_message(update, context):\n",
    "    \"\"\"Maneja los mensajes de texto.\"\"\"\n",
    "    user_question = update.message.text\n",
    "    print(f\"Mensaje de texto recibido: {user_question}\")\n",
    "    await context.bot.send_chat_action(chat_id=update.message.chat_id, action=telegram.constants.ChatAction.TYPING)\n",
    "    await process_and_reply(update, context, user_question)\n",
    "\n",
    "async def handle_voice_message(update, context):\n",
    "    \"\"\"Maneja los mensajes de voz.\"\"\"\n",
    "    print(\"Mensaje de voz recibido. Procesando...\")\n",
    "    await context.bot.send_chat_action(chat_id=update.message.chat_id, action=telegram.constants.ChatAction.TYPING)\n",
    "    \n",
    "    file_path = None\n",
    "    try:\n",
    "        voice_file_id = update.message.voice.file_id\n",
    "        voice_file = await context.bot.get_file(voice_file_id)\n",
    "        file_path = f\"audio_{voice_file_id}.ogg\"\n",
    "        await voice_file.download_to_drive(file_path)\n",
    "        \n",
    "        audio_file_uploaded = genai.upload_file(path=file_path)\n",
    "        \n",
    "        prompt_transcripcion = \"Transcribe el siguiente audio de forma precisa. Devuelve solo el texto.\"\n",
    "        response = model.generate_content([prompt_transcripcion, audio_file_uploaded])\n",
    "        transcribed_text = response.text\n",
    "        \n",
    "        print(f\"Audio transcrito como: '{transcribed_text}'\")\n",
    "        await process_and_reply(update, context, transcribed_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el audio: {e}\")\n",
    "        await update.message.reply_text(\"Lo siento, hubo un problema al procesar tu mensaje de voz.\")\n",
    "    finally:\n",
    "        if file_path and os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"Archivo temporal de audio eliminado: {file_path}\")\n",
    "\n",
    "async def button_callback_handler(update, context):\n",
    "    \"\"\"Maneja los clics en los botones.\"\"\"\n",
    "    query = update.callback_query\n",
    "    await query.answer()\n",
    "    \n",
    "    user_question = query.data\n",
    "    print(f\"Botón presionado. Pregunta: {user_question}\")\n",
    "    await query.edit_message_text(text=f\"Entendido. Buscando información sobre: '{user_question}'\")\n",
    "    await process_and_reply(update, context, user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3627b-362d-4f6e-a589-c0182fcf9605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando el bot...\n",
      "El bot se está ejecutando. Presiona Ctrl+C en la terminal o interrumpe el Kernel en Jupyter para detenerlo.\n",
      "Mensaje de texto recibido: Software\n",
      "Mensaje de voz recibido. Procesando...\n",
      "Audio transcrito como: 'Buenas, ¿venden zapatos?\n",
      "'\n",
      "Archivo temporal de audio eliminado: audio_AwACAgEAAxkBAANUaIUl7Yu2-1rXnBFKQcACX2zVj5wAAjwFAALHAylEzypdBIEyvq02BA.ogg\n",
      "Mensaje de texto recibido: Hola?\n",
      "Mensaje de texto recibido: J\n",
      "Mensaje de texto recibido: Hardware\n",
      "Botón presionado. Pregunta: ¿Qué servicios ofrecen?\n",
      "Mensaje de voz recibido. Procesando...\n",
      "Audio transcrito como: 'Pues les venden las zapatillas.\n",
      "'\n",
      "Archivo temporal de audio eliminado: audio_AwACAgEAAxkBAANgaIUn5q4z3NFCoO_rXk-xmXipRusAAj0FAALHAylEoeC-nOdNgsY2BA.ogg\n",
      "Botón presionado. Pregunta: ¿Qué servicios ofrecen?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No error handlers are registered, logging exception.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 32, in read\n",
      "    with map_exceptions(exc_map):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\request\\_httpxrequest.py\", line 273, in do_request\n",
      "    res = await self._client.request(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpx\\_client.py\", line 1540, in request\n",
      "    return await self.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 393, in handle_async_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\ext\\_utils\\networkloop.py\", line 115, in network_retry_loop\n",
      "    if not await do_action():\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\ext\\_utils\\networkloop.py\", line 108, in do_action\n",
      "    return action_cb_task.result()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\asyncio\\futures.py\", line 202, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\asyncio\\tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\ext\\_updater.py\", line 340, in polling_action_cb\n",
      "    updates = await self.bot.get_updates(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\ext\\_extbot.py\", line 670, in get_updates\n",
      "    updates = await super().get_updates(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\_bot.py\", line 4611, in get_updates\n",
      "    await self._post(\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\_bot.py\", line 698, in _post\n",
      "    return await self._do_post(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\ext\\_extbot.py\", line 370, in _do_post\n",
      "    return await super()._do_post(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\_bot.py\", line 727, in _do_post\n",
      "    result = await request.post(\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\request\\_baserequest.py\", line 197, in post\n",
      "    result = await self._request_wrapper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\request\\_baserequest.py\", line 304, in _request_wrapper\n",
      "    code, payload = await self.do_request(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\atoro\\anaconda3\\envs\\BOTCAMPIA\\Lib\\site-packages\\telegram\\request\\_httpxrequest.py\", line 297, in do_request\n",
      "    raise NetworkError(f\"httpx.{err.__class__.__name__}: {err}\") from err\n",
      "telegram.error.NetworkError: httpx.ReadError: \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Función principal que configura y ejecuta el bot.\"\"\"\n",
    "    \n",
    "    print(\"Iniciando el bot...\")\n",
    "    \n",
    "    application = Application.builder().token(TELEGRAM_TOKEN).build()\n",
    "\n",
    "    # Añadir todos los manejadores\n",
    "    application.add_handler(CommandHandler(\"start\", start))\n",
    "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "    application.add_handler(MessageHandler(filters.VOICE, handle_voice_message))\n",
    "    application.add_handler(CallbackQueryHandler(button_callback_handler))\n",
    "\n",
    "    # Ejecutar el bot hasta que se interrumpa\n",
    "    print(\"El bot se está ejecutando. Presiona Ctrl+C en la terminal o interrumpe el Kernel en Jupyter para detenerlo.\")\n",
    "    application.run_polling()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780cbeb4-7033-4396-9b5d-3cb52f6405ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987e0b6-aa0f-4053-ae7e-fcf592742dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
